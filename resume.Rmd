---
title: Elena Eggl's Resume"
author: Dr. Elena Eggl
date: "`r Sys.Date()`"
output:
  pagedown::html_resume:
    css: ['css/custom_resume.css', 'css/styles.css', 'resume']
    # set it to true for a self-contained HTML page but it'll take longer to render
    self_contained: true
---


```{r, include=FALSE}
knitr::opts_chunk$set(
  results='asis', 
  echo = FALSE
)
library(tidyverse)
library(glue)
library(googlesheets4)
source("parsing_functions.R")
# ======================================================================
# These variables determine how the the data is loaded and how the exports are
# done.

# Is data stored in google sheets? If no data will be gather from the csvs/
# folder in project
using_googlesheets <- TRUE

# Just the copied URL from the sheet
positions_sheet_loc <- "https://docs.google.com/spreadsheets/d/10PJCOb_3RXxu5-bdShK9mIg9HbrzCveO5f8MTqq1R9s"

# Is this sheet available for anyone to read? If you're using a private sheet
# set this to false and go to gather_data.R and run the data loading manually
# once to cache authentication
sheet_is_publicly_readable <- TRUE

# Is the goal of this knit to build a document that is exported to PDF? If so
# set this to true to have links turned into footnotes at the end of the
# document
PDF_EXPORT <- FALSE


# A global (gasp) variable that holds all the links that were inserted for
# placement at the end
links <- c()

# ======================================================================
# Now we source two external scripts. One contains functions for building the
# text output and the other loads up our data from either googlesheets or csvs

# Functions for building sections from CSV data
# source('parsing_functions.R') 

# Load data for CV/Resume
# source('gather_data.R')

if(sheet_is_publicly_readable){
  # This tells google sheets to not try and authenticate. Note that this will only
  # work if your sheet has sharing set to "anyone with link can view"
  sheets_deauth()
} else {
  # My info is in a public sheet so there's no need to do authentication but if you want
  # to use a private sheet, then this is the way you need to do it.
  # designate project-specific cache so we can render Rmd without problems
  options(gargle_oauth_cache = ".secrets")
  
  # Need to run this once before knitting to cache an authentication token
  # googlesheets4::sheets_auth()
}
position_data <- read_sheet(positions_sheet_loc, sheet = "entries", skip = 1)
skills        <- read_sheet(positions_sheet_loc, sheet = "language_skills", skip = 1)
text_blocks   <- read_sheet(positions_sheet_loc, sheet = "text_blocks", skip = 1)
contact_info  <- read_sheet(positions_sheet_loc, sheet = "contact_info", skip = 1)


# Now we just need to filter down the position data to include less verbose
# categories and only the entries we have designated for the resume
position_data <- position_data %>% 
  filter(in_resume) %>% 
  mutate(
    # Build some custom sections by collapsing others
    section = case_when(
      section %in% c('research_positions', 'industry_positions') ~ 'positions', 
      section %in% c('data_science_writings', 'by_me_press') ~ 'writings',
      TRUE ~ section
    )
  ) 
```



Aside
================================================================================


![logo](buidl.png){width=100%}

Contact {#contact}
--------------------------------------------------------------------------------

```{r}
contact_info %>% 
  glue_data("- <i class='fa fa-{icon}'></i> {contact}")
```



Language Skills {#skills}
--------------------------------------------------------------------------------

```{r}
build_skill_bars(skills)
```



Certificates {#certificates}
--------------------------------------------------------------------------------

Google Data Analytics Professional Certificate (7/2021)


More info {#more-info}
--------------------------------------------------------------------------------

See full CV at [github.com/elenaeggl/cv](https://github.com/elenaeggl/cv) for more complete list of positions and publications.


Disclaimer {#disclaimer}
--------------------------------------------------------------------------------

Made w/ [**pagedown**](https://github.com/rstudio/pagedown). 

Source code: [github.com/elenaeggl/cv](https://github.com/elenaeggl/cv).

Last updated on `r Sys.Date()`.



Main
================================================================================

Dr. Elena Eggl {#title}
--------------------------------------------------------------------------------

Physicist with a PhD in X-ray imaging and a passion for data. Several years of industry experience working as an application engineer in the laser industry with a strong focus on data analysis. Proficiency in data collection, data cleaning, statistical analysis, data mining, and data visualization using SQL, Python, R, spreadsheets and Tableau.


Education {data-icon=graduation-cap data-concise=true}
--------------------------------------------------------------------------------

```{r}
position_data %>% print_section('education')
```



Selected Positions {data-icon=suitcase}
--------------------------------------------------------------------------------

```{r}
position_data %>% print_section('positions')
```



<!-- Selected Writing {data-icon=newspaper} -->
<!-- -------------------------------------------------------------------------------- -->

<!-- ```{r} -->
<!-- position_data %>% print_section('writings') -->
<!-- ``` -->


